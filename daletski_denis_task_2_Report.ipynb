{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline --no-import-all\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "\n",
    "def read_data(data_file, images_dir, is_train=True):\n",
    "    data = []\n",
    "    header = []\n",
    "    with open(data_file) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 0:\n",
    "                header = np.array(re.split(r\"\\s*,\\s*\", line.strip()))\n",
    "                continue\n",
    "            line_data = re.split(r\"\\s*,\\s*\", line.strip())\n",
    "            data.append(line_data)\n",
    "            \n",
    "    X = np.array(data)\n",
    "    header = np.array(header)\n",
    "    \n",
    "    if is_train: # extract targets\n",
    "        y = X[:, 1].astype(int)\n",
    "        X = np.hstack((X[:, 0].reshape(-1, 1), X[:, 2:]))\n",
    "        header = np.hstack((header[0], header[2:]))\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    X = pd.DataFrame(X, columns=header).set_index(\"Id\")\n",
    "    images = np.array(X['Poster'].apply(lambda img_path: plt.imread(os.path.join(images_dir, img_path))))\n",
    "    \n",
    "    return X.drop('Poster', axis=1), images, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData, trainImages, trainY = read_data(\"task_2_data/train.csv\", \"task_2_data/posters/\")\n",
    "testData, testImages, testY = read_data(\"task_2_data/test.csv\", \"task_2_data/posters/\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features extraction\n",
    "\n",
    "I implement DataTransformer class which does the following:\n",
    "* Extracts color histograms of posters\n",
    "* Applies one-hot encoding on categorical parameters (language, rating, country)\n",
    "\n",
    "We have too litle training dataset for convolutional networks or some other sophisticated methods, so I decided to use only color histograms of images as features extracted from posters, and use them with other features of movies like rating etc. in classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import copy\n",
    "\n",
    "class DataTransformer:\n",
    "    def __init__(self):\n",
    "        self._lang_encoder = (LabelEncoder(), OneHotEncoder())\n",
    "        self._country_encoder = (LabelEncoder(), OneHotEncoder())\n",
    "        self._rating_encoder = (LabelEncoder(), OneHotEncoder())\n",
    "        self._hist_bins = 8\n",
    "        \n",
    "    def fit_encoder(self, encoder, strings):\n",
    "        classes = encoder[0].fit_transform(strings).reshape(-1, 1)\n",
    "        encoder[1].fit(classes)\n",
    "        \n",
    "    def encode_strings(self, encoder, strings):\n",
    "        classes = encoder[0].transform(strings).reshape(-1, 1)\n",
    "        return encoder[1].transform(classes).toarray()\n",
    "    \n",
    "    def color_histograms(self, images):\n",
    "        \"\"\" calculate color histograms of posters \"\"\"\n",
    "        # initialize with zeroes\n",
    "        hists = pd.DataFrame(\n",
    "            np.zeros((images.shape[0], 3 * self._hist_bins)),\n",
    "            columns=[\"bin%d\" % i for i in range(3 * self._hist_bins)]\n",
    "        )\n",
    "        \n",
    "        # calculate histograms and fill data frame\n",
    "        for i in range(images.shape[0]):\n",
    "            hists.iloc[i, :] = np.array([\n",
    "                cv2.calcHist([channel], [0], None, [self._hist_bins], [0, 256])\n",
    "                for channel in cv2.split(images[i])\n",
    "            ]).reshape((1, -1))\n",
    "        \n",
    "        return hists\n",
    "            \n",
    "        \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        x, images = X\n",
    "        \n",
    "        hist_bins = fit_params.get(\"hist_bins\")\n",
    "        all_langs = fit_params.get(\"all_langs\") # list of all langs to prepare language encoder\n",
    "        all_ratings = fit_params.get(\"all_ratings\") \n",
    "        all_countries = fit_params.get(\"all_countries\")\n",
    "        \n",
    "        if hist_bins is not None:\n",
    "            self._hist_bins = hist_bins\n",
    "            \n",
    "        if all_langs is not None:\n",
    "            self.fit_encoder(self._lang_encoder, all_langs)\n",
    "        else:\n",
    "            self.fit_encoder(self._lang_encoder, x['Language'].unique()) \n",
    "        \n",
    "        if all_countries is not None:\n",
    "            self.fit_encoder(self._country_encoder, all_countries)\n",
    "        else:\n",
    "            self.fit_encoder(self._country_encoder, x['Country'].unique())\n",
    "            \n",
    "        if all_countries is not None:\n",
    "            self.fit_encoder(self._rating_encoder, all_ratings)\n",
    "        else:\n",
    "            self.fit_encoder(self._rating_encoder, x['Rating'].unique())\n",
    "            \n",
    "        return self\n",
    "     \n",
    "    def transform(self, X, **transform_params):  \n",
    "        x, images = X\n",
    "        data = x.copy()\n",
    "        \n",
    "        data.loc[data['Language'] == 'None', 'Language'] = ''        \n",
    "        data.loc[data['Rating'] == 'Not Rated', 'Rating'] = ''\n",
    "        data.loc[data['Rating'] == 'Unrated', 'Rating'] = ''\n",
    "        \n",
    "        # one_hot_encoded langs, countries and ratings\n",
    "        langs = pd.DataFrame(self.encode_strings(self._lang_encoder, data['Language']), index=data.index)\n",
    "        countries = pd.DataFrame(self.encode_strings(self._country_encoder, data['Country']), index=data.index)\n",
    "        ratings = pd.DataFrame(self.encode_strings(self._rating_encoder, data['Rating']), index=data.index)\n",
    "\n",
    "        ######### color histograms of posters ############\n",
    "        hists = self.color_histograms(images).set_index(data.index)\n",
    "        ########## result frame ###########\n",
    "                                    \n",
    "        new_data = pd.concat((\n",
    "            data[['Duration']],\n",
    "            data.loc[:, 'Action':'Western'],\n",
    "            langs,\n",
    "            countries,\n",
    "            hists,\n",
    "            ratings\n",
    "        ), axis=1, join_axes=[data.index])\n",
    "                \n",
    "        return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "Now I will use my feature extractor in pipeline with a classifier. Random forests and Adaboost will be used for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeRF = Pipeline([(\"tr\", DataTransformer()), (\"classifier\", RandomForestClassifier() )])\n",
    "pipeADA = Pipeline([(\"tr\", DataTransformer()), (\"classifier\", AdaBoostClassifier() )])\n",
    "\n",
    "all_langs = pd.concat((trainData['Language'], testData['Language'])).unique()\n",
    "all_countries = pd.concat((trainData['Country'], testData['Country'])).unique()\n",
    "all_ratings = pd.concat((trainData['Rating'], testData['Rating'])).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def CV(model, n_folds=10):\n",
    "    dataFolds = np.split(trainData[:3620], n_folds)\n",
    "    imgFolds = np.split(trainImages[:3620], n_folds)\n",
    "    yFolds = np.split(trainY[:3620], n_folds)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    def split_on_fold(data, fold, is_pandas = False):\n",
    "        if is_pandas:\n",
    "            tr_data = pd.concat((*data[:fold], *data[(fold+1):]))\n",
    "        else:\n",
    "            tr_data = np.concatenate((*data[:fold], *data[(fold+1):]))\n",
    "        val_data = data[fold]\n",
    "        return tr_data, val_data\n",
    "\n",
    "    for fold in tqdm.tqdm(range(n_folds)):\n",
    "        trD, valD = split_on_fold(dataFolds, fold, True)\n",
    "        trI, valI = split_on_fold(imgFolds, fold)\n",
    "        trY, valY = split_on_fold(yFolds, fold)\n",
    "\n",
    "        model.fit(\n",
    "            (trD, trI),\n",
    "            trY,\n",
    "            tr__all_langs=all_langs, # fit params for translator like list of all languages, ratings, countries\n",
    "            tr__all_countries=all_countries,\n",
    "            tr__all_ratings=all_ratings,\n",
    "            tr__hist_bins=6\n",
    "        )\n",
    "\n",
    "        scores.append(model.score((valD, valI), valY))\n",
    "\n",
    "    plt.bar(range(len(scores)), scores)\n",
    "    print(\"average %d-fold validation accuracy: %f\" % (n_folds, np.average(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:17<00:00,  3.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average 5-fold validation accuracy: 0.795856\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDejYAywAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e0dc365f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CV(pipeADA, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:15<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average 5-fold validation accuracy: 0.768508\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nktQg4y5JDfp/J4Ar5yp30jsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e09902c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CV(pipeRF, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, AdaBoost gives a better result, so let's use it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting on full training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pipeADA\n",
    "\n",
    "model.fit(\n",
    "    (trainData, trainImages),\n",
    "    trainY,\n",
    "    tr__all_langs=all_langs,\n",
    "    tr__all_countries=all_countries,\n",
    "    tr__all_ratings=all_ratings,\n",
    "    tr__hist_bins=6\n",
    ")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the output and saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(model.predict_proba((testData, testImages))[:,1], index=testData.index, columns=['Probability'])\n",
    "\n",
    "outfile = \"daletski_denis_task_2_predictions.csv\"\n",
    "predictions.to_csv(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another model I tried to use her was a milti-input CNN. First it took posters, then after convolution layers there was another input for other movies data. All this data + output of convolution layers then passed through dense layes. So this network used spatial features of posters plus other movies data. But there are not enough training data to train CNN and get a satisfactory accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
